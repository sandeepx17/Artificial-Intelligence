{"cells":[{"cell_type":"markdown","metadata":{"id":"EAiHVEoWHy_D"},"source":["# Deep Convolutional Q-Learning for Pac-Man"]},{"cell_type":"markdown","metadata":{"id":"tjO1aK3Ddjs5"},"source":["## Part 0 - Installing the required packages and importing the libraries"]},{"cell_type":"markdown","metadata":{"id":"NwdRB-ZLdrAV"},"source":["### Installing Gymnasium"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35951,"status":"ok","timestamp":1717772393733,"user":{"displayName":"Mohan Sandeep","userId":"11501353829611233669"},"user_tz":-330},"id":"dbnq3XpoKa_7","outputId":"0d6a047e-5d60-4f76-bddd-2a4a169ee03f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy\u003e=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions\u003e=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.1)\n","Requirement already satisfied: farama-notifications\u003e=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy\u003e=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (1.25.2)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n","Requirement already satisfied: typing-extensions\u003e=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (4.12.1)\n","Requirement already satisfied: farama-notifications\u003e=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n","Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.4.2)\n","Requirement already satisfied: shimmy[atari]\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.2.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2-\u003egymnasium[accept-rom-license,atari]) (8.1.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2-\u003egymnasium[accept-rom-license,atari]) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2-\u003egymnasium[accept-rom-license,atari]) (4.66.4)\n","Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2-\u003egymnasium[accept-rom-license,atari]) (0.6.1)\n","Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]\u003c1.0,\u003e=0.1.0-\u003egymnasium[accept-rom-license,atari]) (0.8.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1-\u003eshimmy[atari]\u003c1.0,\u003e=0.1.0-\u003egymnasium[accept-rom-license,atari]) (6.4.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eautorom[accept-rom-license]~=0.4.2-\u003egymnasium[accept-rom-license,atari]) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eautorom[accept-rom-license]~=0.4.2-\u003egymnasium[accept-rom-license,atari]) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eautorom[accept-rom-license]~=0.4.2-\u003egymnasium[accept-rom-license,atari]) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eautorom[accept-rom-license]~=0.4.2-\u003egymnasium[accept-rom-license,atari]) (2024.6.2)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","swig is already the newest version (4.0.2-1ubuntu1).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n","Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy\u003e=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.25.2)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n","Requirement already satisfied: typing-extensions\u003e=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.12.1)\n","Requirement already satisfied: farama-notifications\u003e=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n","Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.3.5)\n","Requirement already satisfied: pygame\u003e=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n","Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.2.1)\n"]}],"source":["!pip install gymnasium\n","!pip install \"gymnasium[atari, accept-rom-license]\"\n","!apt-get install -y swig\n","!pip install gymnasium[box2d]"]},{"cell_type":"markdown","metadata":{"id":"H-wes4LZdxdd"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1717772393734,"user":{"displayName":"Mohan Sandeep","userId":"11501353829611233669"},"user_tz":-330},"id":"Ho_25-9_9qnu"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from collections import deque\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"markdown","metadata":{"id":"m7wa0ft8e3M_"},"source":["## Part 1 - Building the AI"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717772393734,"user":{"displayName":"Mohan Sandeep","userId":"11501353829611233669"},"user_tz":-330},"id":"qug5CaJ5Iabd"},"outputs":[],"source":["class Network(nn.Module):\n","  def __init__(self,action_size, seed=42):\n","    super(Network,self).__init__()\n","    self.seed = torch.manual_seed(seed)\n","    self.conv1=nn.Conv2d(3, 32, kernel_size=8, stride=4)\n","    self.bn1 = nn.BatchNorm2d(32)\n","    self.conv2=nn.Conv2d(32, 64, kernel_size=4,stride=2)\n","    self.bn2 = nn.BatchNorm2d(64)\n","    self.conv3=nn.Conv2d(64, 64, kernel_size=3, stride=1)\n","    self.bn3 = nn.BatchNorm2d(64)\n","    self.conv4=nn.Conv2d(64, 128, kernel_size=3, stride=1)\n","    self.bn4 = nn.BatchNorm2d(128)\n","    self.fc1=nn.Linear(10*10*128, 512)\n","    self.fc2=nn.Linear(512, 256)\n","    self.fc3=nn.Linear(256, action_size )\n","\n","  def forward(self, state):\n","    x = F.relu(self.bn1(self.conv1(state)))\n","    x = F.relu(self.bn2(self.conv2(x)))\n","    x = F.relu(self.bn3(self.conv3(x)))\n","    x = F.relu(self.bn4(self.conv4(x)))\n","    x = x.view(x.size(0),-1)\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    return self.fc3(x)\n"]},{"cell_type":"markdown","metadata":{"id":"dlYVpVdHe-i6"},"source":["### Creating the architecture of the Neural Network"]},{"cell_type":"markdown","metadata":{"id":"rUvCfE_mhwo2"},"source":["## Part 2 - Training the AI"]},{"cell_type":"markdown","metadata":{"id":"WWCDPF22lkwc"},"source":["### Setting up the environment"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717772393734,"user":{"displayName":"Mohan Sandeep","userId":"11501353829611233669"},"user_tz":-330},"id":"0UBbi4H3TJLb","outputId":"111654dc-38ef-4865-cebb-ac584d4c8db9"},"outputs":[{"name":"stdout","output_type":"stream","text":["State Shape:  (210, 160, 3)\n","State Size:  210\n","Number of actions:  9\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment MsPacmanDeterministic-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  logger.deprecation(\n"]}],"source":["import gymnasium as gym\n","env = gym.make('MsPacmanDeterministic-v0',full_action_space= False)\n","state_shape = env.observation_space.shape\n","state_size = env.observation_space.shape[0]\n","number_actions=env.action_space.n\n","print('State Shape: ',state_shape)\n","print('State Size: ',state_size)\n","print('Number of actions: ',number_actions)"]},{"cell_type":"markdown","metadata":{"id":"Bx6IdX3ciDqH"},"source":["### Initializing the hyperparameters"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1717772393734,"user":{"displayName":"Mohan Sandeep","userId":"11501353829611233669"},"user_tz":-330},"id":"z-rXDadnTOyD"},"outputs":[],"source":["learning_rate = 5e-4\n","minibatch_size =64\n","discount_factor = 0.99\n"]},{"cell_type":"markdown","metadata":{"id":"U2bDShIEkA5V"},"source":["### Preprocessing the frames"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":828,"status":"ok","timestamp":1717772394554,"user":{"displayName":"Mohan Sandeep","userId":"11501353829611233669"},"user_tz":-330},"id":"CCdp0BoOT4Mp"},"outputs":[],"source":["from PIL import Image\n","from torchvision import transforms\n","\n","def preprocess_frame(frame):\n","  frame = Image.fromarray(frame)\n","  preprocess = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])\n","  return preprocess(frame).unsqueeze(0)\n"]},{"cell_type":"markdown","metadata":{"id":"imMdSO-HAWra"},"source":["### Implementing the DCQN class"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1717772394555,"user":{"displayName":"Mohan Sandeep","userId":"11501353829611233669"},"user_tz":-330},"id":"Poq9PUssW6dR"},"outputs":[],"source":["class Agent():\n","\n","  def __init__(self , action_size):\n","    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    self.action_size = action_size\n","    self.local_qnetwork = Network( action_size).to(self.device)\n","    self.target_qnetwork = Network( action_size).to(self.device)\n","    self.optimizer = optim.Adam(self.local_qnetwork.parameters(), lr = learning_rate)\n","    self.memory = deque(maxlen=10000)\n","\n","  def step(self, state, action, reward, next_state, done):\n","    state = preprocess_frame(state)\n","    next_state = preprocess_frame(next_state)\n","    self.memory.append((state, action, reward, next_state, done))\n","    if len(self.memory) \u003e minibatch_size:\n","      experiences = random.sample(self.memory, minibatch_size)\n","      self.learn(experiences, discount_factor)\n","\n","  def act(self, state, epsilon = 0.):\n","    state = preprocess_frame(state).to(self.device)\n","    self.local_qnetwork.eval()\n","    with torch.no_grad():\n","      action_values = self.local_qnetwork(state)\n","    self.local_qnetwork.train()\n","    if random.random() \u003e epsilon:\n","      return np.argmax(action_values.cpu().data.numpy())\n","    else:\n","      return random.choice(np.arange(self.action_size))\n","\n","  def learn(self, experiences, discount_factor):\n","    states, actions, rewards, next_states, dones = zip(*experiences)\n","    states = torch.from_numpy(np.vstack(states)).float().to(self.device)\n","    actions = torch.from_numpy(np.vstack(actions)).long().to(self.device)\n","    rewards = torch.from_numpy(np.vstack(rewards)).float().to(self.device)\n","    next_states = torch.from_numpy(np.vstack(next_states)).float().to(self.device)\n","    dones = torch.from_numpy(np.vstack(dones).astype(np.uint8)).float().to(self.device)\n","    next_q_targets = self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1)\n","    q_targets = rewards + discount_factor * next_q_targets * (1 - dones)\n","    q_expected = self.local_qnetwork(states).gather(1, actions)\n","    loss = F.mse_loss(q_expected, q_targets)\n","    self.optimizer.zero_grad()\n","    loss.backward()\n","    self.optimizer.step()\n","\n","\n",""]},{"cell_type":"markdown","metadata":{"id":"yUg95iBpAwII"},"source":["### Initializing the DCQN agent"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717772394555,"user":{"displayName":"Mohan Sandeep","userId":"11501353829611233669"},"user_tz":-330},"id":"GJVkEdodK_L4"},"outputs":[],"source":["agent = Agent(number_actions)"]},{"cell_type":"markdown","metadata":{"id":"CK6Zt_gNmHvm"},"source":["### Training the DCQN agent"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jBVU-gM8Lcwg"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode 12\tAverage Score: 291.67"]}],"source":["number_episodes = 2000\n","maximum_number_timesteps_per_episode = 10000\n","epsilon_starting_value = 1.0\n","epsilon_ending_value = 0.01\n","epsilon_decay_value = 0.995\n","epsilon = epsilon_starting_value\n","scores_on_100_episodes = deque(maxlen= 100)\n","\n","for episode in range(1,number_episodes+1):\n","  state, _ =env.reset()\n","  score = 0\n","  for t in range(maximum_number_timesteps_per_episode):\n","    action = agent.act(state,epsilon)\n","    next_state, reward, done,_,_=env.step(action)\n","    agent.step(state,action,reward,next_state,done)\n","    state=next_state\n","    score+=reward\n","    if done:\n","      break\n","  scores_on_100_episodes.append(score)\n","  epsilon=max(epsilon_ending_value ,epsilon_decay_value*epsilon)\n","  print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)),end=\"\")\n","  if episode % 100 ==0:\n","    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)))\n","    if np.mean(scores_on_100_episodes)\u003e=500.0:\n","       print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode-100, np.mean(scores_on_100_episodes)))\n","       torch.save(agent.local_qnetwork.state_dict(),'chekpoint.pth')\n","       break\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-0WhhBV8nQdf"},"source":["## Part 3 - Visualizing the results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb9nVvU2Okhk"},"outputs":[],"source":["import glob\n","import io\n","import base64\n","import imageio\n","from IPython.display import HTML, display\n","from gym.wrappers.monitoring.video_recorder import VideoRecorder\n","\n","def show_video_of_model(agent, env_name):\n","    env = gym.make(env_name, render_mode='rgb_array')\n","    state, _ = env.reset()\n","    done = False\n","    frames = []\n","    while not done:\n","        frame = env.render()\n","        frames.append(frame)\n","        action = agent.act(state)\n","        state, reward, done, _, _ = env.step(action)\n","    env.close()\n","    imageio.mimsave('video.mp4', frames, fps=30)\n","\n","show_video_of_model(agent, 'MsPacmanDeterministic-v0')\n","\n","def show_video():\n","    mp4list = glob.glob('*.mp4')\n","    if len(mp4list) \u003e 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        display(HTML(data='''\u003cvideo alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\"\u003e\n","                \u003csource src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /\u003e\n","             \u003c/video\u003e'''.format(encoded.decode('ascii'))))\n","    else:\n","        print(\"Could not find video\")\n","\n","show_video()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","provenance":[{"file_id":"1dz5dOAOesQTXsK26MX2GzhwngRE97spW","timestamp":1717753716307},{"file_id":"1nqb-KnVe1EsZF-03Iba7T3cZFsnVRl4H","timestamp":1695853702757}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}